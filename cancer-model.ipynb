{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9307595,"sourceType":"datasetVersion","datasetId":5593457},{"sourceId":194303065,"sourceType":"kernelVersion"},{"sourceId":196859680,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Description\n\nThe code in this notebook is presented almost as-is. You can find the full solution [here](https://github.com/ilyanovo/isic-2024).\n\nThis solution achieves a score of 0.17264 on the private leaderboard and 0.18611 on the public leaderboard.\n\nIt is not the best solution. Replacing the Edgenext model with a model trained on synthetic data resulted in a score of 0.17332 on the private leaderboard.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, cv2\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nfrom sklearn.utils import resample\n\nimport optuna\n\nfrom tqdm import tqdm\n\n\nimport os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\n\nimport h5py\nfrom PIL import Image\nfrom io import BytesIO\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-14T02:08:08.575930Z","iopub.execute_input":"2024-11-14T02:08:08.576805Z","iopub.status.idle":"2024-11-14T02:08:21.813923Z","shell.execute_reply.started":"2024-11-14T02:08:08.576773Z","shell.execute_reply":"2024-11-14T02:08:21.813032Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\n\nnew_num_cols = [\n    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\n\n\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\nspecial_cols = ['count_per_patient', \"tbp_lv_areaMM2_patient\", \"tbp_lv_areaMM2_bp\"] #'count_per_patient_bp'\nfeature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols ","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:21.815594Z","iopub.execute_input":"2024-11-14T02:08:21.816218Z","iopub.status.idle":"2024-11-14T02:08:21.832158Z","shell.execute_reply.started":"2024-11-14T02:08:21.816190Z","shell.execute_reply":"2024-11-14T02:08:21.831040Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\ntest_h5 = root / 'test-image.hdf5'\n\n# Set up device and random seed\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n\n# device = torch.device(\"cpu\")\n\nCONFIG = {\n    \"seed\": 42,\n    \"epochs\": 500,\n    \"img_size\": 336, #336,\n    \"model_name\": 'eva02_small_patch14_336.mim_in22k_ft_in1k',\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 2000,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"group_col\": 'patient_id',\n    \"device\": device\n}\n\ntransformations_base = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(\n            mean=[0.4815, 0.4578, 0.4082], \n            std=[0.2686, 0.2613, 0.2758], \n            max_pixel_value=255.0,\n            p=1.0\n        ),\n    ToTensorV2(),\n    ], p=1.)\n\ndef set_seed(random_seed):\n    random.seed(random_seed)\n    torch.manual_seed(random_seed)\n    np.random.seed(random_seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(random_seed)\n        torch.cuda.manual_seed_all(random_seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \n        \nclass ISICModel(nn.Module):\n    def __init__(self, model_name, num_classes=1, drop_path_rate=0, drop_rate=0, pretrained=True, checkpoint_path=None):\n        super(ISICModel, self).__init__()\n        self.model = timm.create_model(\n            model_name, \n            pretrained=pretrained, \n            heckpoint_path=checkpoint_path,\n            drop_rate=drop_rate, \n            drop_path_rate=drop_path_rate)\n\n        in_features = self.model.head.in_features\n        self.model.head = nn.Linear(in_features, num_classes)\n        self.sigmoid = nn.Sigmoid() if num_classes == 1 else nn.Softmax()\n\n    def forward(self, images):\n        return self.sigmoid(self.model(images))\n    \n    \n    \nclass ISICDataset(Dataset):\n    def __init__(self, df, file_hdf, transforms=None):\n        self.df = df\n        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n        self.isic_ids = df['isic_id'].values\n        self.targets = df['target'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.isic_ids)\n    \n    def __getitem__(self, index):\n        isic_id = self.isic_ids[index]\n        img = np.array( Image.open(BytesIO(self.fp_hdf[isic_id][()])) )\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'target': target,\n        }\n\n    \ndef prepare_loaders(df_train, h5_file, augmentations, CONFIG, num_workers=10):\n    \n    train_dataset = ISICDataset(df_train, h5_file, transforms=augmentations)\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=num_workers, shuffle=False, pin_memory=True, drop_last=False)\n    \n    return train_loader\n\n\n@torch.inference_mode()\ndef generate_predictions(model, dataloader, device):\n    model.eval()\n    \n\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    predictions_all = []\n    targets_all = []\n    for step, data in bar:        \n        images = data['image'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n\n        outputs = model(images).squeeze()\n\n        predictions_all.append(outputs.cpu().numpy())\n        targets_all.append(targets.cpu().numpy())\n    \n    gc.collect()\n\n    targets_all = np.concatenate(targets_all)\n    predictions_all = np.concatenate(predictions_all)\n    \n    return targets_all, predictions_all\n\n\nmodel = ISICModel(CONFIG['model_name'], pretrained=False, num_classes=3)\nmodel.load_state_dict( torch.load('../input/skin-models-base/ema_small_pretrained', weights_only=True) )\nmodel.to(CONFIG['device']);\n\ntest_df[\"path\"] = '../input/isic-2024-challenge/test-image/image/' + test_df['isic_id'] + \".jpg\"\ntest_df['target'] = 0\ndata_loader_test = prepare_loaders(test_df, test_h5, transformations_base, CONFIG, num_workers=2)\n\ntargets_all, predictions_all = generate_predictions(model, data_loader_test, device)\n\ntest_df['old_set_0'] = predictions_all[:, 0]\ntest_df['old_set_1'] = predictions_all[:, 1]\ntest_df['old_set_2'] = predictions_all[:, 2]\n\ntest_df[['isic_id', 'old_set_0', 'old_set_1', 'old_set_2']].to_parquet(\n    'old_data_model_forecast__test.parquet')\nmodel.to('cpu');","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:21.833717Z","iopub.execute_input":"2024-11-14T02:08:21.834194Z","iopub.status.idle":"2024-11-14T02:08:25.280576Z","shell.execute_reply.started":"2024-11-14T02:08:21.834168Z","shell.execute_reply":"2024-11-14T02:08:25.279681Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU: Tesla P100-PCIE-16GB\nNumber of GPUs: 1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\n\ntest_df[\"path\"] = '../input/isic-2024-challenge/test-image/image/' + test_df['isic_id'] + \".jpg\"\ntest_df['target'] = 0\ndata_loader_test = prepare_loaders(test_df, test_h5, transformations_base, CONFIG, num_workers=2)\n\n\nbase_model_path = \"../input/skin-models-base\"\nfor base_model_index in range(5):\n    base_model_full_path = os.path.join(base_model_path, f\"eva_model__{base_model_index}\")\n    \n    model = ISICModel(CONFIG['model_name'], pretrained=False, num_classes=1)\n    model.load_state_dict(torch.load(base_model_full_path, weights_only=True))\n    model.to(CONFIG['device']);\n    targets_all, predictions_all = generate_predictions(model, data_loader_test, device)\n    test_df[f\"predictions__{base_model_index}\"] = predictions_all\n    model.to('cpu');\n    \ntest_df = test_df[\n    ['isic_id', 'patient_id',\n         'predictions__0', 'predictions__1', 'predictions__2', 'predictions__3', 'predictions__4']\n].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:25.282902Z","iopub.execute_input":"2024-11-14T02:08:25.283208Z","iopub.status.idle":"2024-11-14T02:08:33.851724Z","shell.execute_reply.started":"2024-11-14T02:08:25.283180Z","shell.execute_reply":"2024-11-14T02:08:33.850447Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n100%|██████████| 1/1 [00:00<00:00, 11.18it/s]\n100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n100%|██████████| 1/1 [00:00<00:00, 11.25it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def add_pation_norm(df, column_name: str, column_name_new: str):\n    df = df.merge(\n        df.groupby(\"patient_id\").agg(**{\n            column_name_new: pd.NamedAgg(column_name, 'mean')\n        }).reset_index(), how=\"left\", on=[\"patient_id\"])\n\n    df[column_name_new] = df[column_name] / df[column_name_new]\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:33.853142Z","iopub.execute_input":"2024-11-14T02:08:33.853466Z","iopub.status.idle":"2024-11-14T02:08:33.859347Z","shell.execute_reply.started":"2024-11-14T02:08:33.853439Z","shell.execute_reply":"2024-11-14T02:08:33.858323Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"oof_forecasts_eva = pd.read_parquet('../input/skin-models-base/oof_forecasts_eva.parquet')\noof_forecasts_eva_agg = oof_forecasts_eva.groupby('fold_n').agg(**{\n        \"mean_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"mean\"),\n        \"std_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"std\")})\n\n#Scaling works better on both public and private leaderboards when it is done using values from just one fold\nfor i in range(5):\n    test_df[f'predictions__{i}'] = (\n        test_df[f'predictions__{i}'] - oof_forecasts_eva_agg.loc[0].mean_preds\n    ) / oof_forecasts_eva_agg.loc[0].std_preds\n    \ntest_df[\"predictions_eva\"] = test_df[[f'predictions__{i}' for i in range(5)]].mean(axis=1)\ntest_df_eva = test_df.copy()\n\n\n# tmp_predictions_all_rank_pr\noof_forecasts_eva = oof_forecasts_eva[['isic_id', 'patient_id', 'tmp_predictions_all__pr']].rename(columns={\n    'tmp_predictions_all__pr': 'predictions_eva'\n})\n\n\ntest_df_eva = add_pation_norm(\n    test_df_eva, column_name='predictions_eva', column_name_new='predictions_eva_m')\noof_forecasts_eva = add_pation_norm(\n    oof_forecasts_eva, column_name='predictions_eva', column_name_new='predictions_eva_m')","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:33.860533Z","iopub.execute_input":"2024-11-14T02:08:33.860853Z","iopub.status.idle":"2024-11-14T02:08:35.329294Z","shell.execute_reply.started":"2024-11-14T02:08:33.860830Z","shell.execute_reply":"2024-11-14T02:08:35.328498Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class ISICModelEdgnet(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None, *args, **kwargs):\n        super(ISICModelEdgnet, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes, global_pool='avg')\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, images):\n        return self.sigmoid(self.model(images))","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:35.330543Z","iopub.execute_input":"2024-11-14T02:08:35.331272Z","iopub.status.idle":"2024-11-14T02:08:35.337419Z","shell.execute_reply.started":"2024-11-14T02:08:35.331236Z","shell.execute_reply":"2024-11-14T02:08:35.336487Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ISICModelEdgnet(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None, *args, **kwargs):\n        super(ISICModelEdgnet, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes, global_pool='avg')\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, images):\n        return self.sigmoid(self.model(images))\n    \n\nCONFIG = {\n    \"seed\": 42,\n    \"epochs\": 500,\n    \"img_size\": 256, #336,\n#     \"model_name\": 'eva02_small_patch14_336.mim_in22k_ft_in1k',\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 2000,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"group_col\": 'patient_id',\n    \"device\": device\n}\n\ntransformations_base = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(\n            mean=[0.4815, 0.4578, 0.4082], \n            std=[0.2686, 0.2613, 0.2758], \n            max_pixel_value=255.0,\n            p=1.0\n        ),\n    ToTensorV2(),\n    ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:35.338830Z","iopub.execute_input":"2024-11-14T02:08:35.339262Z","iopub.status.idle":"2024-11-14T02:08:35.349637Z","shell.execute_reply.started":"2024-11-14T02:08:35.339230Z","shell.execute_reply":"2024-11-14T02:08:35.348787Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\n\ntest_df[\"path\"] = '../input/isic-2024-challenge/test-image/image/' + test_df['isic_id'] + \".jpg\"\ntest_df['target'] = 0\ndata_loader_test = prepare_loaders(test_df, test_h5, transformations_base, CONFIG, num_workers=2)\n\n\nbase_model_path = \"../input/skin-models-base\"\nfor base_model_index in range(5):\n    base_model_full_path = os.path.join(base_model_path, f\"edg_model__{base_model_index}\")\n    \n    model = ISICModelEdgnet('edgenext_base.in21k_ft_in1k', pretrained=False, num_classes=1)\n    model.load_state_dict(torch.load(base_model_full_path, weights_only=True))\n    model.to(CONFIG['device']);\n    targets_all, predictions_all = generate_predictions(model, data_loader_test, device)\n    test_df[f\"predictions__{base_model_index}\"] = predictions_all\n    model.to('cpu');\n    \noof_forecasts_edgenext = pd.read_parquet('../input/skin-models-base/oof_forecasts_edgenext_base.parquet')\noof_forecasts_edgenext_agg = oof_forecasts_edgenext.groupby('fold_n').agg(**{\n        \"mean_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"mean\"),\n        \"std_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"std\")})\n\n#Scaling works better on both public and private leaderboards when it is done using values from just one fold\nfor i in range(5):\n    test_df[f'predictions__{i}'] = (\n        test_df[f'predictions__{i}'] - oof_forecasts_edgenext_agg.loc[0].mean_preds\n    ) / oof_forecasts_edgenext_agg.loc[0].std_preds\n    \ntest_df[\"predictions_edg\"] = test_df[[f'predictions__{i}' for i in range(5)]].mean(axis=1)\ntest_df = test_df[['isic_id', 'patient_id', 'predictions_edg']].reset_index(drop=True)\ntest_df_edg = test_df.copy()\n\n\noof_forecasts_edgenext = oof_forecasts_edgenext[['isic_id', 'patient_id', 'tmp_predictions_all__pr']].rename(columns={\n    'tmp_predictions_all__pr': 'predictions_edg'\n})\n\n\ntest_df_edg = add_pation_norm(\n    test_df_edg, column_name='predictions_edg', column_name_new='predictions_edg_m')\noof_forecasts_edgenext = add_pation_norm(\n    oof_forecasts_edgenext, column_name='predictions_edg', column_name_new='predictions_edg_m')","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:35.350965Z","iopub.execute_input":"2024-11-14T02:08:35.351677Z","iopub.status.idle":"2024-11-14T02:08:44.522106Z","shell.execute_reply.started":"2024-11-14T02:08:35.351649Z","shell.execute_reply":"2024-11-14T02:08:44.520988Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n100%|██████████| 1/1 [00:00<00:00, 14.68it/s]\n100%|██████████| 1/1 [00:00<00:00, 14.18it/s]\n100%|██████████| 1/1 [00:00<00:00, 15.06it/s]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n        )\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n        )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            tbp_lv_areaMM2_patient = pl.col('tbp_lv_areaMM2').sum().over('patient_id'),\n        )\n        .with_columns(\n            tbp_lv_areaMM2_bp = pl.col('tbp_lv_areaMM2').sum().over(['patient_id', 'anatom_site_general']),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:44.527018Z","iopub.execute_input":"2024-11-14T02:08:44.527345Z","iopub.status.idle":"2024-11-14T02:08:44.556301Z","shell.execute_reply.started":"2024-11-14T02:08:44.527318Z","shell.execute_reply":"2024-11-14T02:08:44.555329Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def preprocess(df_train, df_test):\n    global cat_cols\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n    \n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:44.557397Z","iopub.execute_input":"2024-11-14T02:08:44.557723Z","iopub.status.idle":"2024-11-14T02:08:44.571366Z","shell.execute_reply.started":"2024-11-14T02:08:44.557690Z","shell.execute_reply":"2024-11-14T02:08:44.570439Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:44.572449Z","iopub.execute_input":"2024-11-14T02:08:44.572874Z","iopub.status.idle":"2024-11-14T02:08:44.584954Z","shell.execute_reply.started":"2024-11-14T02:08:44.572848Z","shell.execute_reply":"2024-11-14T02:08:44.584070Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Data Read & Feature Engineering","metadata":{}},{"cell_type":"code","source":"# '../input/old-models-predictions/old_data_model_forecast.parquet'\ndef add_old_model_preds(df_train, path):\n    old_data_model_preds = pd.read_parquet(path) #old_data_model_forecast\n    feature_cols_new = []\n    df_train = df_train.merge(old_data_model_preds, how=\"left\", on=[\"isic_id\"])\n    feature_cols_new += [i for i in old_data_model_preds.columns if i!='isic_id']\n    df_train = df_train.merge(\n        df_train.groupby(\"patient_id\").agg(**{\n            \"old_set_0_m\": pd.NamedAgg('old_set_0', 'mean'),\n            \"old_set_1_m\": pd.NamedAgg('old_set_1', 'mean'),\n            \"old_set_2_m\": pd.NamedAgg('old_set_2', 'mean')\n        }).reset_index(), how=\"left\", on=[\"patient_id\"])\n\n    df_train['old_set_0_m'] = df_train['old_set_0'] / df_train['old_set_0_m']\n    df_train['old_set_1_m'] = df_train['old_set_1'] / df_train['old_set_1_m']\n    df_train['old_set_2_m'] = df_train['old_set_2'] / df_train['old_set_2_m']\n    feature_cols_new += ['old_set_0_m', 'old_set_1_m', 'old_set_2_m']\n    return df_train, feature_cols_new","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:44.586065Z","iopub.execute_input":"2024-11-14T02:08:44.586409Z","iopub.status.idle":"2024-11-14T02:08:44.595087Z","shell.execute_reply.started":"2024-11-14T02:08:44.586383Z","shell.execute_reply":"2024-11-14T02:08:44.594050Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_test = read_data(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train, df_test = preprocess(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:44.596214Z","iopub.execute_input":"2024-11-14T02:08:44.596511Z","iopub.status.idle":"2024-11-14T02:08:51.283778Z","shell.execute_reply.started":"2024-11-14T02:08:44.596486Z","shell.execute_reply":"2024-11-14T02:08:51.283009Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for col in feature_cols: \n    df_test[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n    \ncat_columns = list(df_test.select_dtypes('category').columns)\nfor col in feature_cols[76:77]:\n    if col not in cat_columns:\n        if df_test[col].isna().mean() != 1:\n            filler = df_test[col].median()\n        else:\n            filler = 0\n        df_test[col] = df_test[col].fillna(filler)\n    else:\n        vc = df_test[col].value_counts()\n        if vc.shape[0] == 0:\n            filler = 0\n        else:\n            filler = vc.index[0]\n    \n        df_test[col] = df_test[col].fillna(filler)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:51.285299Z","iopub.execute_input":"2024-11-14T02:08:51.285642Z","iopub.status.idle":"2024-11-14T02:08:51.404608Z","shell.execute_reply.started":"2024-11-14T02:08:51.285615Z","shell.execute_reply":"2024-11-14T02:08:51.403593Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/44406708.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_test[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import StandardScaler\n\ntop_lof_features = [\n        'tbp_lv_H','hue_contrast',\n       'age_normalized_nevi_confidence_2', 'tbp_lv_deltaB',\n       'color_uniformity', 'tbp_lv_z',\n       'clin_size_long_diam_mm', 'tbp_lv_y',\n       'position_distance_3d', 'hue_contrast',\n       'tbp_lv_stdLExt', 'mean_hue_difference',\n       'age_normalized_nevi_confidence',\n       'lesion_visibility_score',\n       'position_distance_3d',\n       'tbp_lv_minorAxisMM', 'tbp_lv_Hext']","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:51.406133Z","iopub.execute_input":"2024-11-14T02:08:51.406996Z","iopub.status.idle":"2024-11-14T02:08:51.412508Z","shell.execute_reply.started":"2024-11-14T02:08:51.406959Z","shell.execute_reply":"2024-11-14T02:08:51.411617Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def get_lof_score(df_train, top_lof_features):\n    scalled_array = StandardScaler().fit_transform(df_train[top_lof_features])\n    outiler_factors = []\n    for patient_id in tqdm(df_train.patient_id.unique()):\n        mask = (df_train['patient_id'] == patient_id).values\n        sum_mask = sum(mask)\n        if sum_mask < 3:\n            continue\n        patient_emb = scalled_array[mask]\n        clf = LocalOutlierFactor(n_neighbors=min(30, sum_mask))\n        clf.fit_predict(patient_emb)\n\n\n        outiler_factors.append(pd.DataFrame(\n            {\"isic_id\": df_train[mask].index.values,\n            \"of\": clf.negative_outlier_factor_}))\n\n    if len(outiler_factors) == 0:\n        df_train['of'] = -1\n        return df_train\n    \n    outiler_factors = pd.concat(outiler_factors).reset_index(drop=True)\n\n    df_train = df_train.merge(outiler_factors.set_index('isic_id'), how=\"left\", left_index=True, right_index=True)\n    df_train['of'] = df_train['of'].fillna(-1)\n    return df_train\n\ndf_train = get_lof_score(df_train, top_lof_features)\ndf_test = get_lof_score(df_test, top_lof_features)\n\nfeature_cols += ['of']","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:08:51.413689Z","iopub.execute_input":"2024-11-14T02:08:51.413961Z","iopub.status.idle":"2024-11-14T02:11:51.104695Z","shell.execute_reply.started":"2024-11-14T02:08:51.413937Z","shell.execute_reply":"2024-11-14T02:11:51.103582Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 1042/1042 [02:58<00:00,  5.84it/s]\n100%|██████████| 3/3 [00:00<00:00, 5614.86it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df_train, extra_f = add_old_model_preds(df_train, '../input/old-models-predictions/old_data_model_forecast.parquet')\ndf_test, extra_f = add_old_model_preds(df_test, 'old_data_model_forecast__test.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:51.106207Z","iopub.execute_input":"2024-11-14T02:11:51.106635Z","iopub.status.idle":"2024-11-14T02:11:52.655235Z","shell.execute_reply.started":"2024-11-14T02:11:51.106599Z","shell.execute_reply":"2024-11-14T02:11:52.653903Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"df_train = df_train.merge(oof_forecasts_eva, how=\"left\", on='isic_id')\ndf_test = df_test.merge(test_df_eva, how=\"left\", on='isic_id')\n\n \nfeature_cols += extra_f\nfeature_cols += ['predictions_eva', 'predictions_eva_m']","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:52.656791Z","iopub.execute_input":"2024-11-14T02:11:52.657394Z","iopub.status.idle":"2024-11-14T02:11:53.389887Z","shell.execute_reply.started":"2024-11-14T02:11:52.657358Z","shell.execute_reply":"2024-11-14T02:11:53.389085Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df_train = df_train.merge(oof_forecasts_edgenext, how=\"left\", on='isic_id')\ndf_test = df_test.merge(test_df_edg, how=\"left\", on='isic_id')\n\nfeature_cols += ['predictions_edg', 'predictions_edg_m']","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:53.391049Z","iopub.execute_input":"2024-11-14T02:11:53.391391Z","iopub.status.idle":"2024-11-14T02:11:54.643997Z","shell.execute_reply.started":"2024-11-14T02:11:53.391364Z","shell.execute_reply":"2024-11-14T02:11:54.643134Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### Optuna HyperParam Tuned Models","metadata":{}},{"cell_type":"code","source":"lgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           200,\n    'boosting_type':    'gbdt',\n    \"device\" : \"gpu\",\n    'random_state':     seed,\n    'lambda_l1':        0.08758718919397321, \n    'lambda_l2':        0.0039689175176025465, \n    'learning_rate':    0.03231007103195577, \n    'max_depth':        4, \n    'num_leaves':       103, \n    'colsample_bytree': 0.8329551585827726, \n    'colsample_bynode': 0.4025961355653304, \n    'bagging_fraction': 0.7738954452473223, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 85, \n    'scale_pos_weight': 2.7984184778875543,\n}\n\ncb_params = {\n    'loss_function':     'Logloss',\n    'iterations':        200,\n    'verbose':           False,\n    'random_state':      seed,\n    'max_depth':         7, \n    'learning_rate':     0.06936242010150652, \n    'scale_pos_weight':  2.6149345838209532, \n    'l2_leaf_reg':       6.216113851699493, \n    'subsample':         0.6249261779711819, \n    'min_data_in_leaf':  24,\n    'cat_features':      cat_cols,\n}\n\nxgb_params  = {\n    'enable_categorical': True,\n    'tree_method':        'hist',\n    'random_state':       seed,\n    'learning_rate':      0.08501257473292347, \n    'lambda':             8.879624125465703, \n    'alpha':              0.6779926606782505, \n    'max_depth':          6, \n    'subsample':          0.6012681388711075, \n    'colsample_bytree':   0.8437772277074493, \n    'colsample_bylevel':  0.5476090898823716, \n    'colsample_bynode':   0.9928601203635129, \n    'scale_pos_weight':   3.29440313334688,\n    \"device\": \"cuda\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:54.645159Z","iopub.execute_input":"2024-11-14T02:11:54.645441Z","iopub.status.idle":"2024-11-14T02:11:54.654429Z","shell.execute_reply.started":"2024-11-14T02:11:54.645416Z","shell.execute_reply":"2024-11-14T02:11:54.653455Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### Cross Validation","metadata":{}},{"cell_type":"code","source":"def custom_metric_raw(y_hat, y_true):\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc\n\n\ndef custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    partial_auc = custom_metric_raw(y_hat, y_true)\n    return partial_auc\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:54.655609Z","iopub.execute_input":"2024-11-14T02:11:54.655960Z","iopub.status.idle":"2024-11-14T02:11:54.666420Z","shell.execute_reply.started":"2024-11-14T02:11:54.655935Z","shell.execute_reply":"2024-11-14T02:11:54.665601Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from pydantic import BaseModel\n\nclass ModelConfigCB(BaseModel):\n    iterations: int = 1000\n    learning_rate: float = 0.06936242010150652\n    l2_leaf_reg: float = 6.216113851699493\n    loss_function: str = \"Logloss\"\n    bagging_temperature: float = 1\n    random_seed: int = seed\n    border_count: int = 128\n    grow_policy: str = \"SymmetricTree\" #Depthwise Lossguide\n    min_data_in_leaf: int = 24\n    depth: int  = 7\n    do_sample: bool = True","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:54.667763Z","iopub.execute_input":"2024-11-14T02:11:54.668110Z","iopub.status.idle":"2024-11-14T02:11:54.885961Z","shell.execute_reply.started":"2024-11-14T02:11:54.668078Z","shell.execute_reply":"2024-11-14T02:11:54.885121Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def run_model_old_cb(cb_params, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    metric_list = []\n    models = []\n    for random_seed in range(1, 10):\n        tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n        metrics_ev_df = []\n        test_forecast = []\n        val_forecast = []\n        for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n            train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            \n            for col in ['predictions_edg', 'predictions_edg_m', 'predictions_eva', 'predictions_eva_m']:\n                train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n            train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n            val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n        \n            cb_model = Pipeline([\n                ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n                ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=seed)),\n                ('classifier', cb.CatBoostClassifier(**cb_params)),\n            ])\n            \n            cb_model.fit(train_slice_x, train_slice_y)\n            preds_cb = cb_model.predict_proba(val_slice_x)[:, 1]\n            metric = custom_metric_raw(preds_cb, val_slice_y.values)\n            metric_list.append(metric)\n            models.append(cb_model)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models\n    \n    \ndef run_model_old_lgb(lgb_params, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    metric_list = []\n    models = []\n    for random_seed in range(1, 10):\n        random_seed = random_seed * 10 + 17\n        tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n        metrics_ev_df = []\n        test_forecast = []\n        val_forecast = []\n        for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n            train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            \n            for col in ['predictions_edg', 'predictions_edg_m', 'predictions_eva', 'predictions_eva_m']:\n                train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n            train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n            val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n        \n            cb_model = Pipeline([\n                ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=random_seed)),\n                ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=random_seed)),\n                ('classifier', lgb.LGBMClassifier(**lgb_params)),\n            ])\n            \n            cb_model.fit(train_slice_x, train_slice_y)\n            preds_cb = cb_model.predict_proba(val_slice_x)[:, 1]\n            metric = custom_metric_raw(preds_cb, val_slice_y.values)\n            metric_list.append(metric)\n            models.append(cb_model)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models\n    \n    \ndef run_model_old_xgb(xgb_params, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    metric_list = []\n    models = []\n    for random_seed in range(1, 10):\n        random_seed = random_seed * 10 + 88\n        tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n        metrics_ev_df = []\n        test_forecast = []\n        val_forecast = []\n        for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n            train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            \n            for col in ['predictions_edg', 'predictions_edg_m', 'predictions_eva', 'predictions_eva_m']:\n                train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n                \n            train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n            val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n        \n            cb_model = Pipeline([\n                ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=random_seed)),\n                ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=random_seed)),\n                ('classifier', xgb.XGBClassifier(**xgb_params)),\n            ])\n            \n            cb_model.fit(train_slice_x, train_slice_y)\n            preds_cb = cb_model.predict_proba(val_slice_x)[:, 1]\n            metric = custom_metric_raw(preds_cb, val_slice_y.values)\n            metric_list.append(metric)\n            models.append(cb_model)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models\n    \n    \ndef run_model_cb(trial , test=False, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    model_config_cb = ModelConfigCB(\n        iterations = 2000,\n        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.08) if not test else trial.get('learning_rate'),\n        l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1, 20) if not test else trial.get('l2_leaf_reg'),\n        random_strength = trial.suggest_float('random_strength', 0, 5) if not test else trial.get('random_strength'),\n        loss_function = \"Logloss\",\n        depth = trial.suggest_int('depth', 2, 8) if not test else trial.get('depth'),\n        bagging_temperature = trial.suggest_float('bagging_temperature', 0, 10) if not test else trial.get('bagging_temperature'),\n        border_count = trial.suggest_categorical('border_count', [128, 256]) if not test else trial.get('border_count'),\n        grow_policy = trial.suggest_categorical('grow_policy', [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]) if not test else trial.get('grow_policy'),\n        random_seed=42,\n        min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 8, 40) if not test else trial.get('min_data_in_leaf'),\n    )\n    \n    models = []\n    metric_list = []\n    \n    with tqdm() as pbar:\n        for random_seed in range(1, 10):\n            tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n            metrics_ev_df = []\n            test_forecast = []\n            val_forecast = []\n            for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n                train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n                val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n\n                train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n                val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n                \n                if model_config_cb.do_sample:\n                    cb_model = Pipeline([\n                        ('sampler_1', RandomOverSampler(sampling_strategy=0.003 , random_state=random_seed)),\n                        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=random_seed)),\n                    ])\n\n                    train_slice_x, train_slice_y = cb_model.fit_resample(train_slice_x, train_slice_y)\n                \n                for col in ['predictions_edg', 'predictions_edg_m', 'predictions_eva', 'predictions_eva_m']:\n                    train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n                \n                \n                clf_catboost = cb.CatBoostClassifier(\n                    loss_function=model_config_cb.loss_function,\n                    eval_metric='AUC',\n                    task_type='GPU',\n                    learning_rate=model_config_cb.learning_rate,\n                    od_wait=100,\n                    random_state=random_seed,\n                    depth=model_config_cb.depth,\n                    l2_leaf_reg=model_config_cb.l2_leaf_reg,\n                    min_data_in_leaf=model_config_cb.min_data_in_leaf,\n                    bagging_temperature=model_config_cb.bagging_temperature,\n                    border_count=model_config_cb.border_count,\n                    grow_policy=model_config_cb.grow_policy, \n                    devices='0',\n                    iterations=model_config_cb.iterations,\n                )\n\n                train_pool = cb.Pool(train_slice_x, train_slice_y.values, cat_features=cat_cols) \n                val_pool = cb.Pool(val_slice_x, val_slice_y.values, cat_features=cat_cols) \n\n                clf_catboost.fit(train_pool, eval_set=val_pool,verbose=False)\n                preds_cb = clf_catboost.predict_proba(val_slice_x)[:, 1]\n                metric = custom_metric_raw(preds_cb, val_slice_y.values)\n                metric_list.append(metric)\n                models.append(clf_catboost)\n                pbar.update(1)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:54.887211Z","iopub.execute_input":"2024-11-14T02:11:54.887499Z","iopub.status.idle":"2024-11-14T02:11:54.931122Z","shell.execute_reply.started":"2024-11-14T02:11:54.887473Z","shell.execute_reply":"2024-11-14T02:11:54.930188Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"columns_to_drop = [\n 'tbp_lv_B',\n 'tbp_lv_C',\n 'tbp_lv_H',\n 'tbp_lv_L',\n 'tbp_lv_radial_color_std_max',\n 'tbp_lv_y',\n 'tbp_lv_z',\n 'luminance_contrast',\n 'lesion_color_difference',\n 'normalized_lesion_size',\n 'tbp_lv_norm_border_patient_norm',\n 'lesion_color_difference_patient_norm',\n 'age_normalized_nevi_confidence_2_patient_norm',\n 'tbp_lv_deltaA']","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:54.932306Z","iopub.execute_input":"2024-11-14T02:11:54.933132Z","iopub.status.idle":"2024-11-14T02:11:54.944305Z","shell.execute_reply.started":"2024-11-14T02:11:54.933094Z","shell.execute_reply":"2024-11-14T02:11:54.943386Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"model_config_cb = ModelConfigCB(**{\n     'learning_rate': 0.02606161517843435,\n     'l2_leaf_reg': 18.04422276698195,\n     'random_strength': 4.7069580783889995,\n     'depth': 6,\n     'bagging_temperature': 0.8735940473548339,\n     'border_count': 256,\n     'grow_policy': 'Lossguide',\n     'min_data_in_leaf': 38})\n\nmetric_list, models_cb = run_model_cb(\n    model_config_cb.dict(), test=True, reduce=False, columns_to_drop=columns_to_drop)\n\nprint(np.mean(metric_list))","metadata":{"execution":{"iopub.status.busy":"2024-11-14T02:11:54.945513Z","iopub.execute_input":"2024-11-14T02:11:54.945874Z"},"trusted":true},"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]Default metric period is 5 because AUC is/are not implemented for GPU\n1it [00:35, 35.04s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n2it [00:46, 21.10s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n3it [00:55, 15.67s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n4it [01:03, 12.75s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n5it [01:12, 11.23s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n6it [01:22, 10.79s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n7it [01:30,  9.83s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n8it [01:37,  8.89s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n9it [01:48,  9.59s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n10it [01:56,  9.24s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n11it [02:13, 11.57s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n12it [02:20, 10.13s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n13it [02:27,  9.18s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n14it [02:34,  8.65s/it]Default metric period is 5 because AUC is/are not implemented for GPU\n15it [02:42,  8.35s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"metric_list, models_lgb = run_model_old_lgb(\n    lgb_params, reduce=False, columns_to_drop=columns_to_drop)\n\nprint(np.mean(metric_list))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metric_list, models_xgb = run_model_old_xgb(\n    xgb_params, reduce=False, columns_to_drop=columns_to_drop)\n\nprint(np.mean(metric_list))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"for col in feature_cols: \n    df_test[col].replace([np.inf, -np.inf], np.nan, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model_predictions(models_list, df_test, feature_cols, columns_to_drop):\n    df_test_size = int(df_test.shape[0] // 2)\n    predictions_tmp = None\n    for model in models_list:\n        preds_tmp = model.predict_proba(\n                df_test[[i for i in feature_cols if i not in columns_to_drop]])[:, 1]\n\n        preds_tmp = pd.DataFrame({\"preds\": preds_tmp})\n        preds_tmp = preds_tmp['preds'].rank(pct=True)\n\n        if predictions_tmp is None:\n            predictions_tmp = preds_tmp.values\n        else:\n            predictions_tmp += preds_tmp.values\n\n    predictions_tmp = predictions_tmp / len(models_list)\n    return predictions_tmp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_cb = get_model_predictions(models_cb, df_test, feature_cols, columns_to_drop)\npredictions_xgb = get_model_predictions(models_xgb, df_test, feature_cols, columns_to_drop)\npredictions_lgb = get_model_predictions(models_lgb, df_test, feature_cols, columns_to_drop)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = (\n    predictions_lgb +\n    predictions_cb +\n    predictions_xgb\n) / 3\n\ndf_subm['target'] = predictions\n\n\ndf_subm.to_csv('submission.csv')\ndf_subm.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}